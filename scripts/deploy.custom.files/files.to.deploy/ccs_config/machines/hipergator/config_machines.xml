<?xml version="1.0"?>
<config_machines version="2.0">

  <machine MACH="hipergator">

    <!--basic system info-->
    <DESC>HiPerGator | hpg-default node | AMD ROME 128 cores per node | slurm</DESC>
    <OS>LINUX</OS>
    <COMPILERS>gnu</COMPILERS> <!--use comma separated list with default first if adding more compiler support-->
    <MPILIBS>openmpi</MPILIBS> <!--use comma separated list like above if adding mpi libs-->

    <!--file system info-->
    <CIME_OUTPUT_ROOT>/blue/gerber/$ENV{USER}/earth_model_output/cime_output_root</CIME_OUTPUT_ROOT> <!--put output wherever is convenient for you-->
    <DIN_LOC_ROOT>/blue/gerber/earth_models/inputdata</DIN_LOC_ROOT> <!--root dir of inputdata-->
    <DIN_LOC_ROOT_CLMFORC>$DIN_LOC_ROOT/atm/datm7</DIN_LOC_ROOT_CLMFORC> <!--clm forcing data located inside inputdata root-->
    <DOUT_S_ROOT>$CIME_OUTPUT_ROOT/archive/$CASE</DOUT_S_ROOT> <!--short term archive files-->
    <BASELINE_ROOT>/blue/gerber/$ENV{USER}/earth_model_output/cesm_baselines</BASELINE_ROOT> <!--system test file out-->

    <!--more misc system info-->
    <CCSM_CPRNC>/blue/gerber/earth_models/shared/cprnc/bld/cprnc</CCSM_CPRNC> <!--linked to shared cprnc build-->
    <GMAKE>make</GMAKE>
    <BATCH_SYSTEM>slurm</BATCH_SYSTEM>
    <SUPPORTED_BY>sgerber@ufl.edu</SUPPORTED_BY>
    <MAX_TASKS_PER_NODE>128</MAX_TASKS_PER_NODE> <!--set for hpg-default cpu-->
    <MAX_MPITASKS_PER_NODE>128</MAX_MPITASKS_PER_NODE> <!--MAX_TASKS_PER_NODE >= MAX_MPITASKS_PER_NODE-->
    <PROJECT_REQUIRED>FALSE</PROJECT_REQUIRED> <!--generally used when tracking grant costs or billing per project-->

    <!--openmpi executable-->
    <mpirun mpilib="default">
      <executable>mpirun</executable>
    </mpirun>

    <!--defines basics of lmod module system-->
    <module_system type="module" allow_error="true">
      <init_path lang="perl">/apps/lmod/lmod/init/perl</init_path>
      <init_path lang="python">/apps/lmod/lmod/init/env_modules_python.py</init_path>
      <init_path lang="csh">/apps/lmod/lmod/init/csh</init_path>
      <init_path lang="sh">/apps/lmod/lmod/init/sh</init_path>
      <cmd_path lang="perl">/apps/lmod/lmod/libexec/lmod perl</cmd_path>
      <cmd_path lang="python">/apps/lmod/lmod/libexec/lmod python</cmd_path>
      <cmd_path lang="sh">module</cmd_path>
      <cmd_path lang="csh">module</cmd_path>

    <!--load order of modules matters. stand alone first, then compiler and dependents-->
    <modules>
      <!--load stand alone modules-->
      <command name="load">cmake/3.26.4</command>
      <command name="load">perl/5.24.1</command> <!--perl >= 5.30 creates python and mpi executable conflicts-->
      <command name="load">python/3.12</command> <!--python may become gcc/openmpi dependent module in future updates-->

      <!--load compiler and openmpi related modules-->
      <command name="load">gcc/14.2.0</command>
      <command name="load">lapack/3.11.0</command> <!--not openmpi dependent-->
      <command name="load">openmpi/5.0.7</command>
      <command name="load">netcdf-c/4.9.3</command>
      <command name="load">netcdf-f/4.6.2</command>
      <command name="load">hdf5/1.14.6</command> <!--needed by netcdf-->
      <command name="load">esmf/8.8.1</command>
    </modules>
    </module_system>

    <!--set environment variables for ctsm, existing env will also be exported-->
    <environment_variables>
      <env name="ESMF_LIBDIR">$ENV{HPC_ESMF_DIR}/lib/libO/Linux.gfortran.64.openmpi.default</env>
      <env name="ESMFMKFILE">$ENV{HPC_ESMF_DIR}/lib/libO/Linux.gfortran.64.openmpi.default/esmf.mk</env>
      <env name="LAPACK_LIBDIR">$ENV{HPC_LAPACK_LIB}</env>

      <!--NETCDF_PATH == NETCDF_C_PATH-->
      <env name="NETCDF_PATH">$ENV{HPC_NETCDF_C_DIR}</env>
      <env name="NETCDF_C_PATH">$ENV{HPC_NETCDF_C_DIR}</env>
      <env name="NETCDF_FORTRAN_PATH">$ENV{HPC_NETCDF_F_DIR}</env>

      <!--link to parallelio built in the shared directory-->
      <env name="PIO">/blue/gerber/earth_models/shared/parallelio/bld</env>
      <env name="PIO_LIBDIR">/blue/gerber/earth_models/shared/parallelio/bld/lib</env>
      <env name="PIO_INCDIR">/blue/gerber/earth_models/shared/parallelio/bld/include</env>

      <!--L3 cache size of hpg-default cpu-->
      <env name="OMP_STACKSIZE">256M</env>
    </environment_variables>

    <resource_limits>
      <resource name="RLIMIT_STACK">-1</resource> <!--python resource limit-->
    </resource_limits>

  </machine>

</config_machines>
